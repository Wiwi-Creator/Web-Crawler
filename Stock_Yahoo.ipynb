{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "希望透過Yahoo奇摩股市網站(https://tw.stock.yahoo.com/)取得關注的股票資料後，存入MySQL DB中，以利後續作資料的分析，正式開發爬蟲程式前，須先針對該網頁做分析。\n",
    "1.\"公司名稱\",\"資料時間\",\"當日行情資料\"為需要取得的資料\n",
    "![title](img/股市網頁.png)\n",
    "2.觀察到上方之網址，最後為股票代號的參數\n",
    "![title](img/股票代號(替換處).png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "class stock:\n",
    "    def init(self):\n",
    "        pass\n",
    "    def scrape(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化股票(Stock)物件時，希望透過用戶能傳入多個股票代碼，以便可以利用Python網頁爬蟲取得不同股票的當日行情資料，所以，在建構式(Constructor)的地方使用*args參數，將傳入的多個股票代碼打包成一個元組(Tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('3481', '6116')\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "class Stock:\n",
    "    # 建構式\n",
    "    def __init__(self, *stock_numbers):\n",
    "        self.stock_numbers = stock_numbers\n",
    "        print(self.stock_numbers)\n",
    "\n",
    "    # 爬取\n",
    "    def scrape(self):\n",
    "        pass\n",
    "stock = Stock(\"3481\",\"6116\") #建立Stock物件\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在scrape()方法(Method)中，利用requests套件發送GET請求到Yahoo奇摩股市的「3481群創」當日行情網頁，取得回傳結果(原始碼)後，使用lxml解析器來建立BeautifulSoup物件。\n",
    "透過「F12」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "class Stock:\n",
    "    # 建構式\n",
    "    def __init__(self, *stock_numbers):\n",
    "        self.stock_numbers = stock_numbers\n",
    "        print(self.stock_numbers)\n",
    "\n",
    "    # 爬取\n",
    "    def scrape(self):\n",
    "        response = requests.get(\"https://tw.stock.yahoo.com/quote/3481.TW\")\n",
    "        soup = BeautifulSoup(response.text,'lxml')\n",
    "        stock_name = soup.find()\n",
    "        stock_date = soup.find()\n",
    "        market_date = stock_date[0:10]\n",
    "        market_time = stock_date[11:16]\n",
    "        \n",
    "        ul =  soup.find()\n",
    "\n",
    "stock = Stock(\"3481\",\"6116\") #建立Stock物件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "23300995598eec4bcf6bd89cf02d1c3675e8b2616661418dbbf5580aa901878d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
